install.packages(stringr)
install.packages("stringr")
protest_data <- read.csv("https://countlove.org/data/data.csv")
# Load the dataset from the URL
protest_data <- read.csv("https://countlove.org/data/data.csv")
library(stringr)
View(protest_data)
View(protest_data)
View(protest_data)
View(protest_data)
protest_data <- read.csv("https://countlove.org/data/data.csv")
summary(protest_data)
View(protest_data)
num_protests <- nrow(protest_data)
print(num_protests)
num_features <- ncol(protest_data)
print(num_features)
num_atendees <- protest_data$Attendees
print(num_attendees)
print(num_atendees)
print(num_atendees)
min_attendees <- min(num_attendees, na.rm = TRUE)
> min_attendees <- min(num_atendees, na.rm = TRUE)
min_attendees <- min(num_atendees, na.rm = TRUE)
num_attendees <- protest_data$Attendees
min_attendees <- min(num_attendees, na.rm = TRUE)
max_attendees <- max(num_attendees, na.rm = TRUE)
mean_attendees <- mean(num_attendees, na.rm = TRUE)
mean_attendees <- mean(num_attendees, na.rm = TRUE)
median_attendees <- median(num_attendees, na.rm = TRUE)
difference_attendees <- mean_attendees - median_attendees
# In this part, you will explore where protests happened.
# (3.a) Extract the `Location` column into a variable called `locations`
# (3.b) How many *unique* locations are in the dataset?
# Save the NUMBER of unique locations in a variable called `num_locations`
# (3.c) How many protests occurred in the state of Washington?
# Use a function from the stringr package to detect the letters "WA" in the
# Location column and filter to only keep WA locations
# Then, calculate the number of protests recorded in Washington
# Save the NUMBER of WA locations in a variable called `num_in_wa`
# (3.d) What proportion of protests occurred in Washington?
# Divide the number of protests in Washington by the total number of protests
# Save this proportion in a variable called `prop_in_wa`
# (3.e) Now, using the same stringr function and building on the code that
# you've written above, write a function `count_protests_in_location()` that
# accepts a location and then returns (not prints) the following sentence:
# "There were [N] protests in [LOCATION]."
# For example: "There were 20 protests in Seattle." "There were 50 protests in
# NY."
# If the location is not found in the dataset, the function should return the
# sentence: "Sorry, that location is not found."
# (3.f) Use your `count_protests_in_location()` function above to compute the
# number of protests in "Washington, DC" and return the resulting message
# Save the resulting message in a variable called `dc_summary`
# (3.g) Use your function above to compute the number of protests in
# "Minneapolis" and return the resulting message
# # Save the resulting message in a variable called `minneapolis_summary`
# (3.h) Let's try to find out how many protests occurred in each state. To do
# so, first use a stringr function to extract the last 2 characters from every
# location and use these 2 characters to create a new vector called `states`
# (3.i) What are the unique states are in the dataset? Create a vector of just the
# unique states in the dataset
# Save the unique states in a variable called `uniq_states`
# Hint: Due to the way the data was collected, you may notice some "nonsense"
# state abbreviations, such as "CE." YOU DO NOT NEED TO FIX THIS, but you may
# reflect to yourself on why this might be happening.
# (3.j) Now apply your `count_protests_in_location` function to every state in
# `uniq_states` by using the `sapply()` function.
# Store all your messages in a variable called `state_summary`
locations <- protest_data$Location
num_locations <- length(unique(locations))
print(num_locations)
library(stringr)
wa_protests <-locations[str_detect(locations, "WA")]
View(protest_data)
num_in_wa <- length(wa_protests)
View(protest_data)
print(wa_protests)
library(stringr)  # ensure the stringr package is loaded
wa_protests <- locations[str_detect(locations, "WA")]
num_in_wa <- length(wa_protests)
View(protest_data)
library(stringr)
wa_protests <- locations[str_detect(locations, "WA")]
num_in_wa <- length(wa_protests)
print(num_in_wa)
prop_in_wa <- num_in_wa / nrow(protest_data)
prop_in_wa <- num_in_wa / nrow(protest_data)
print(prop_in_wa)
count_protests_in_location <- function(location) {
count <- sum(str_detect(locations, regex(location, ignore_case = TRUE)))
if (count > 0) {
return(paste("There were", count, "protests in", location))
} else {
return("Sorry, that location is not found.")
}
}
View(count_protests_in_location)
dc_summary <- count_protests_in_location("Washington, DC")
print(dc_summary)
minneapolis_summary <- count_protests_in_location("Minneapolis")
print(minneapolis_summary)
states <- str_sub(locations, -2)
print(states)
uniq_states <- unique(states)
print(uniq_states)
state_summary <- sapply(uniq_states, count_protests_in_location)
print(state_summary)
dates <- as.Date(protest_data$Date, format="%Y-%m-%d")  # adjust the format string as necessary
dates <- as.Date(protest_data$Date, format="%Y-%m-%d")
print(dates)
most_recent_protest <- max(dates)
print(most_recent_protest)
earliest_protest <- min(dates)
print(earliest_protest)
time_span <- most_recent_protest - earliest_protest
print(time_span)
protests_in_2020 <- dates[dates >= as.Date("2020-01-01") & dates <= as.Date("2020-12-31")]
print(protests_in_2020)
protests_in_2019 <- dates[dates >= as.Date("2019-01-01") & dates <= as.Date("2019-12-31")]
protests_in_2018 <- dates[dates >= as.Date("2018-01-01") & dates <= as.Date("2018-12-31")]
num_protests_in_2018 <- length(protests_in_2018)
print(num_protests_in_2018
print(num_protests_in_2018)
# Assuming 'dates' has already been converted and filtered for each year
num_protests_in_2018 <- length(protests_in_2018)
num_protests_in_2019 <- length(protests_in_2019)
num_protests_in_2020 <- length(protests_in_2020)
num_protests_in_2018 <- length(protests_in_2018)
num_protests_in_2019 <- length(protests_in_2019)
num_protests_in_2020 <- length(protests_in_2020)
purposes <- protest_data$`Event..legacy..see.tags.`
print(purposes)
num_purposes <- length(unique(purposes))
high_level_purposes <- trimws(gsub("\\s*\\(.*\\)", "", purposes))
print(num_purposes)
print(high_level_purposes)
high_level_purposes_table <- table(high_level_purposes)
View(high_level_purposes_table)
install.packages("tinytex")
tinytex::install_tinytex()
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(tidyverse)
library(dplyr)
conflicts prefer(dplyr::filter)
library(dplyr)
conflicts_prefer(dplyr::filter)
# install.packages("devtools")
devtools::install_github("r-lib/conflicted")
install.packages("devtools")
devtools::install_github("r-lib/conflicted")
library(conflicted)
library(dplyr)
library(conflicted)
library(dplyr)
library(dplyr)
conflicts_prefer(dplyr::filter)
https://github.com/nytimes/covid-19-data.git
national <- read_csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/us-national-covid-2023.csv")
states <- read_csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/us-states-covid-2023.csv")
counties <- read_csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/us-counties-covid-2023.csv")
obs_national <- national %>% nrow()
obs_states <- states %>% nrow()
obs_counties <- counties %>% nrow()
obs_national <- national %>% nrow()
obs_states <- states %>% nrow()
obs_counties <- counties %>% nrow()
counties <- read_csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/us-counties-covid-2023.csv")
obs_counties <- counties %>% nrow()
obs_counties <- counties %>% nrow()
obs_counties <- counties %>% nrow()
obs_counties <- counties %>% nrow()
obs_national <- national %>% nrow()
obs_counties <- counties %>% nrow()
print obs_counties <- counties %>% nrow()
print obs_counties
print(obs_counties)
print(obs_states)
print(obs_national)
num_features_national <- national %>% ncol()
num_features_states <- states %>% ncol()
num_features_counties <- counties %>% ncol()
# For the national dataset
print(head(national))
# For the state dataset
print(head(states))
# For the county dataset
print(head(counties))
# For the national dataset
print(obs_national)
# For the state dataset
print(obs_states)
# For the county dataset
print(obs_counties)
num_features_national
num_features_states
num_features_counties
total_us_cases <- national %>%
summarize(total_us_cases = max(cases)) %>%
pull(total_us_cases)
total_us_cases <- national %>%
summarize(total_us_cases = max(cases)) %>%
pull(total_us_cases)
print(total_us_cases)
total_us_deaths <- national %>%
summarize(total_us_deaths = max(deaths)) %>%
pull(total_us_deaths)
print(total_us_deaths)
state_highest_cases <- states %>%
group_by(state) %>%
summarize(total_cases = max(cases)) %>%
arrange(desc(total_cases)) %>%
slice(1) %>%
pull(state)
print(state_highest_cases)
obs_national
num_features_national
num_features_national
num_features_states
num_features_counties
state_highest_cases <- states %>%
group_by(state) %>%
summarize(total_cases = max(cases)) %>%
arrange(desc(total_cases)) %>%
slice(1) %>%
pull(state)
print(state_highest_cases
print(state_highest_cases)
print(state_highest_cases)
num_highest_state <- states %>%
summarize(num_highest_state = max(cases)) %>%
pull(num_highest_state)
print(num_highest_state)
states_with_ratio <- states %>%
group_by(state) %>%
summarize(death_ratio = max(deaths) / max(cases))
state_highest_ratio <- states_with_ratio %>%
filter(death_ratio == max(death_ratio)) %>%
pull(state)
print(state_highest_ratio)
state_lowest_cases <- states %>%
group_by(state) %>%
summarize(total_cases = max(cases)) %>%
arrange(total_cases) %>%
slice(1) %>%
pull(state)
print(state_lowest_cases)
state_lowest_cases <- states %>%
filter(state != "American Samoa") %>%
group_by(state) %>%
summarize(total_cases = max(cases)) %>%
arrange(total_cases) %>%
slice(1) %>%
pull(state)
print(state_lowest_cases)
print(states)
states <- states %>%
group_by(state) %>%
summarize(death_ratio = max(deaths) / max(cases)) %>%
arrange(desc(death_ratio))
state_highest_ratio <- states %>%
slice(1) %>%
pull(state)
print(state_highest_ratio)
state_lowest_cases <- states %>%
slice(n()) %>%
pull(state)
print(state_lowest_cases)
print(state_lowest_cases)
state_lowest_cases <- states %>%
slice(n()) %>%
pull(state)
print(state_lowest_cases)
num_highest_cases_county <- counties %>%
summarize(num_highest_cases_county = max(cases)) %>%
pull(num_highest_cases_county)
print(num_highest_cases_county)
county_highest_cases <- counties %>%
filter(cases == max(counties$cases)) %>%
pull(county)
print(county_highest_cases)
counties <- counties %>%
mutate(location = paste(county, state, sep = ", "))
location_most_deaths <- counties %>%
filter(deaths == max(counties$deaths)) %>%
pull(location)
print(location_most_deaths)
print(location_most_deaths)
location_most_deaths <- counties %>%
filter(deaths == max(counties$deaths)) %>%
pull(location)
print(counties %>%
filter(deaths == max(counties$deaths)))
print(location_most_deaths)
if (any(counties$deaths > 0)) {
location_most_deaths <- counties %>%
filter(deaths == max(counties$deaths)) %>%
pull(location)
print(location_most_deaths)
} else {
print("No deaths recorded in the dataset.")
}
location_most_deaths <- counties %>%
filter(deaths == max(counties$deaths)) %>%
pull(location)
print(location_most_deaths)
print(locations)
national <- national %>%
mutate(new_cases = cases - lag(cases, default = 0))
conflicted::conflicts_prefer(dplyr::lag)
national <- national %>%
mutate(new_cases = cases - lag(cases, default = 0))
national <- national %>%
mutate(new_deaths = deaths - lag(deaths, default = 0))
date_most_cases <- national %>%
filter(new_cases == max(national$new_cases)) %>%
pull(date)
print(date_most_cases)
date_most_deaths <- national %>%
filter(new_deaths == max(national$new_deaths)) %>%
pull(date)
print(date_most_deaths)
most_deaths <- national %>%
filter(date == date_most_deaths) %>%
pull(new_deaths)
print(most_deaths)
highest_cases_in_each_state <- counties %>%
group_by(state) %>%
filter(cases == max(cases)) %>%
ungroup()
print(highest_cases_in_each_state)
highest_cases_washington <- highest_cases_in_each_state %>%
filter(state == "Washington")
print(highest_cases_washington)
lowest_deaths_in_each_state <- counties %>%
group_by(state) %>%
filter(deaths == min(deaths)) %>%
ungroup()
print(lowest_deaths_in_each_state)
total_cases_counties <- counties %>%
group_by(date) %>%
summarize(county_total_cases = sum(cases))
print(total_cases_counties)
all_totals <- inner_join(total_cases_counties, national, by = "date")
national_county_diff <- all_totals %>%
filter(county_total_cases != cases)
num_national_county_diff <- nrow(national_county_diff)
View(states_with_ratio)
# Calculate the total number of COVID-related deaths in each state
total_deaths_by_state <- states %>%
group_by(state) %>%
summarize(total_deaths = sum(deaths))
# Calculate the total number of COVID-related deaths in each state
total_deaths_by_state <- states %>%
group_by(state) %>%
summarize(total_deaths = sum(deaths))
average_new_cases <- mean(national$new_cases, na.rm = TRUE)
print(average_new_cases)
total_deaths_by_state <- states %>%
group_by(state) %>%
summarize(total_deaths = sum(deaths))
average_new_cases_by_state <- national %>%
filter(date >= Sys.Date() - 7) %>%
group_by(state) %>%
summarize(average_new_cases = mean(new_cases, na.rm = TRUE))
high_cases_counties <- counties %>%
filter(cases > 10000)
count_high_cases_counties <- nrow(high_cases_counties)
print(high_cases_counties)
git checkout -b feature-dataset
git checkout -b feature-dataset
gitcheckout -b feature-dataset
git checkout -b new-branch
library(readxl)
Voter_Demographics_Tables_2_ <- read_excel("C:/Users/Savanna/Downloads/Voter Demographics Tables (2).xlsx",
sheet = "City Registration Table")
View(Voter_Demographics_Tables_2_)
git checkout -b dataset
git checkout dataset
head(county demographics)
install.packages("knitr")
library(knitr)
---
```{r, echo=FALSE}
kable(VoterDemographics)
library(knitr)
kable(VoterDemographics)
library(knitr)kable(VoterDemographics)
library(knitr)
kable(Voter_Demographics_Table_2_)
library(knitr)
kable(Voter_Demographics_Tables_2_)
library(knitr)
voterDemographics <- read.csv("Voter_Demographics_Tables_2_.csv")
library(knitr)
kable(county demographics)
library(knitr)
voterDemographics <- read.csv("county demographics.csv")
getwd()
setwd(C:\Users\Savanna\Documents\GitHub\exploratory-analysis-bc-2)
setwd"C:\Users\Savanna\Documents\GitHub\exploratory-analysis-bc-2"
setwd("C:\Users\Savanna\Documents\GitHub\exploratory-analysis-bc-2")
setwd("C:/Users/Savanna/Documents/GitHub/exploratory-analysis-bc-2")
getwd()
library(knitr)
> voterDemographics <- read.csv("county demographics.csv")
library(knitr)
voterDemographics <- read.csv("county demographics.csv")
View(voterDemographics)
kable(voterDemographics)
library(knitr)
voterDemographics <- read.csv("county demographics.csv")
kable(voterDemographics)
install.packages("dplyr")
library(dplyr)
remove.packages("dplyr")
install.packages("dplyr")
library(dplyr)
